{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrUR9H4QhvSNJl75PAKlO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkarshAnilkumar/AML-331-Python-and-Machine-Learning-Lab/blob/main/Naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "#\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import pickle"
      ],
      "metadata": {
        "id": "VLe29SAtv3tT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data\\emails.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "mQ01VSH8yl36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('spam').describe()"
      ],
      "metadata": {
        "id": "D62zutsyv9Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WordCloud to see the frequently used words\n",
        "spam_words = ' '.join(list(df[df['spam'] == 1]['text']))\n",
        "spam_wc = WordCloud(width = 512,height = 512).generate(spam_words)\n",
        "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
        "plt.imshow(spam_wc)\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JQHsmvypv-9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#To test our model we have to split our data into train and test dataset.\n",
        "#We will use 75% for training and remaining 25% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text,df.spam, test_size=0.25)"
      ],
      "metadata": {
        "id": "6shjEFJRwBXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count vectorizer example to convert text to numbers.\n",
        "corpus = [\n",
        "     'This is the first document.', #1\n",
        "     'This document is the second document.', #2\n",
        "     'And this is the third one.', #3\n",
        "     'Is this the first document?', #4\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "#unique words in each of the four document above. We have 9 unique words.\n",
        "#We can take these words and treat each as a feature, as a column. \n",
        "print(vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "Mb7DLP5YwDlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Build a matrix with each of the word. This represents words as count. \n",
        "# We can use these individual features \n",
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "4N0r1bO_wF6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count Vectorizer to convert words into a matrix of features.\n",
        "v = CountVectorizer()\n",
        "X_train_count = v.fit_transform(X_train.values)\n",
        "X_train_count.toarray()[:2]"
      ],
      "metadata": {
        "id": "La8B5_l9wH9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are using Multinomial Naive Bayes model to classify text. For this example we have count of each word to predict\n",
        "# the label ham or spam.\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_count,y_train)"
      ],
      "metadata": {
        "id": "KmrjfJFIwJ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails = [\n",
        "    'trading limit and policy changes  vince -  here '' s a summary of what '' s going to the bod , along with updated policy . feel  free to call me if you have any questions .  regards ,  cassandra .'\n",
        "]\n",
        "emails_count = v.transform(emails)\n",
        "test = model.predict(emails_count)\n",
        "for i in test:\n",
        "    if i == 0:\n",
        "        print(\"ham\")\n",
        "    elif i == 1:\n",
        "        print(\"spam\")"
      ],
      "metadata": {
        "id": "PI8j0VXbwLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the model accurancy score\n",
        "X_test_count = v.transform(X_test)\n",
        "model.score(X_test_count, y_test)"
      ],
      "metadata": {
        "id": "TeHNX04swTnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#save the count vector file\n",
        "pickle.dump(v, open('count_vect', 'wb'))"
      ],
      "metadata": {
        "id": "itbn5ZBZwViS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "pickle.dump(model, open('email_class.pkl', 'wb'))\n"
      ],
      "metadata": {
        "id": "WDL77BLewYVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}